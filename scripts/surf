#!/usr/bin/env python3

"""
surf: A standalone script to surf web (Powered by searx)

Copyright ¬© 2021 Bhupesh Varshney

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.

"""

import urllib.request
import urllib.parse
import json
import pprint
import random
import argparse
import readline
from sys import stdin
from os import isatty

HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36",
    "Content-Type": "application/json",
}

# add/remove your fav searx instances
searx_instances = [
    "https://searx.nevrlands.de/",
    "https://searx.olymp.to/",
    "https://search.mdosch.de/",
    "https://dynabyte.ca/",
]


class colors:
    RED = "\033[31m"
    BLUE = "\033[34m"
    CYAN = "\033[1;36m"
    GREEN = "\033[32m"
    YELLOW = "\033[33m"
    RESET = "\033[m"
    BOLD = "\033[;1m"


# Don't overload one server, might be rate-limited
instance = random.choice(searx_instances)


def request(url, data=None, method=None):
    req = urllib.request.Request(url, headers=HEADERS)
    try:
        with urllib.request.urlopen(req) as response:
            res = json.loads(response.read().decode("utf-8"))
    except urllib.error.URLError as e:
        print(e.reason)
        exit()
    return res


def search(query, show_description):
    data = request(f"{instance}search?q={urllib.parse.quote_plus(query)}&format=json")
    print(f"Using {colors.BOLD}{instance}{colors.RESET}")
    print(f"""Found {colors.BOLD}{len(data["results"])}{colors.RESET} results\n""")

    if len(data["corrections"]) > 0:
        print(
            f"""Did you mean {colors.BOLD}{data["corrections"]}{colors.RESET}?\n"""
        )

    for res in data["results"]:
        print(f"""{colors.BOLD}{colors.YELLOW}{res["title"]}{colors.RESET}""")
        if show_description and res["content"] != "":
            print(f"""   {colors.GREEN}{res["content"]:4}{colors.RESET}""")
        print(
            f"{colors.BOLD}‚ñ∫{colors.RESET} ",
            f"""{colors.CYAN}{res["url"]}{colors.RESET}""",
        )


if __name__ == "__main__":
    is_pipe = not isatty(stdin.fileno())
    parser = argparse.ArgumentParser(description="Surf Internet on Command line")
    parser.add_argument(
        "-q",
        "--query",
        type=str,
        help="Search query",
    )
    parser.add_argument(
        "-s",
        "--show-description",
        action="store_true",
        default=False,
        help="Show link description",
    )
    args = parser.parse_args()
    if is_pipe:
        query = stdin.read()
    elif not args.query:
        query = str(input("\nSearch üîçÔ∏è : "))
    else:
        query = args.query
    search(query, args.show_description)
